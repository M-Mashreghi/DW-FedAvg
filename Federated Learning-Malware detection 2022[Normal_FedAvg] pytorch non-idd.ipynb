{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55b69fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173907af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from federated_utils_fedavg_copy import *\n",
    "\n",
    "import foolbox as fb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4bf76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declear path to your data\n",
    "drebin_data_path = r'H:\\GIT project\\DW-FedAvg\\data\\drebin.csv'\n",
    "malgenome_data_path = r'H:\\GIT project\\DW-FedAvg\\data\\malgenome.csv'\n",
    "kronodroid_data_path = r'H:\\GIT project\\DW-FedAvg\\data\\kronodroid.csv'\n",
    "TUANDROMD_data_path=r'H:\\GIT project\\DW-FedAvg\\data\\TUANDROMD.csv'\n",
    "\n",
    "\n",
    "\n",
    "Drebin_data = pd.read_csv(drebin_data_path, header = None)\n",
    "\n",
    "Malgenome_data = pd.read_csv(malgenome_data_path)\n",
    "\n",
    "Tuandromd_data=pd.read_csv(TUANDROMD_data_path)\n",
    "\n",
    "kronodroid_data=pd.read_csv(kronodroid_data_path)\n",
    "Kronodroid_data = kronodroid_data.iloc[:,range(1,kronodroid_data.shape[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da6c9299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================\n",
      "Working with: Drebin\n",
      "===================================================================================================\n",
      "---------------------------------------------\n",
      "No. of Clients: 5\n",
      "No. of Rounds: 200\n",
      "---------------------------------------------\n",
      "asds\n",
      "Client client_1 has 8419 data samples.\n",
      "asd1\n",
      "Client client_2 has 2527 data samples.\n",
      "asd1\n",
      "Client client_3 has 1768 data samples.\n",
      "asd1\n",
      "Client client_4 has 532 data samples.\n",
      "asd1\n",
      "Client client_5 has 372 data samples.\n",
      "asd1\n",
      "asdas3\n",
      "|=======================|\n",
      "|Traditional FedAvg 2017|\n",
      "|=======================|\n",
      "comm_round: 0 | global_acc: 63.132% | global_loss: 0.632642924785614 | global_f1: 0.0 | global_precision: 1.0 | global_recall: 0.0 | global_auc: 0.9409494152634081| flobal_FPR: 1.0 \n",
      "comm_round: 1 | global_acc: 77.061% | global_loss: 0.4993264973163605 | global_f1: 0.5484293193717278 | global_precision: 1.0 | global_recall: 0.37781785392245265 | global_auc: 0.9745986568793503| flobal_FPR: 0.6221821460775473 \n",
      "comm_round: 2 | global_acc: 94.215% | global_loss: 0.2929442226886749 | global_f1: 0.9188432835820896 | global_precision: 0.9516908212560387 | global_recall: 0.8881875563570785 | global_auc: 0.9850051590913732| flobal_FPR: 0.11181244364292155 \n",
      "comm_round: 3 | global_acc: 95.545% | global_loss: 0.16935649514198303 | global_f1: 0.939366515837104 | global_precision: 0.9427792915531336 | global_recall: 0.9359783588818755 | global_auc: 0.9888632002700866| flobal_FPR: 0.06402164111812443 \n",
      "comm_round: 4 | global_acc: 95.844% | global_loss: 0.12336181849241257 | global_f1: 0.9431559799909051 | global_precision: 0.9513761467889909 | global_recall: 0.9350766456266907 | global_auc: 0.9914667251664417| flobal_FPR: 0.06492335437330929 \n",
      "comm_round: 5 | global_acc: 96.410% | global_loss: 0.10323131829500198 | global_f1: 0.9507299270072993 | global_precision: 0.9621421975992613 | global_recall: 0.939585211902615 | global_auc: 0.9933238081264355| flobal_FPR: 0.060414788097385035 \n",
      "comm_round: 6 | global_acc: 96.875% | global_loss: 0.09206008911132812 | global_f1: 0.9570383912248629 | global_precision: 0.9703429101019463 | global_recall: 0.9440937781785392 | global_auc: 0.9941742391111832| flobal_FPR: 0.05590622182146077 \n",
      "comm_round: 7 | global_acc: 97.473% | global_loss: 0.08507975935935974 | global_f1: 0.965391621129326 | global_precision: 0.9751609935602575 | global_recall: 0.9558160504959423 | global_auc: 0.9946172609474588| flobal_FPR: 0.04418394950405771 \n",
      "comm_round: 8 | global_acc: 97.507% | global_loss: 0.08051226288080215 | global_f1: 0.9658935879945431 | global_precision: 0.9743119266055046 | global_recall: 0.957619477006312 | global_auc: 0.9949510705411371| flobal_FPR: 0.04238052299368801 \n",
      "comm_round: 9 | global_acc: 97.706% | global_loss: 0.07747703045606613 | global_f1: 0.968593536640874 | global_precision: 0.9779411764705882 | global_recall: 0.9594229035166817 | global_auc: 0.9950721536796691| flobal_FPR: 0.0405770964833183 \n",
      "comm_round: 10 | global_acc: 97.706% | global_loss: 0.07476230710744858 | global_f1: 0.9686221009549795 | global_precision: 0.9770642201834863 | global_recall: 0.9603246167718665 | global_auc: 0.9952787072689294| flobal_FPR: 0.03967538322813345 \n",
      "comm_round: 11 | global_acc: 97.673% | global_loss: 0.07282596081495285 | global_f1: 0.9681818181818183 | global_precision: 0.9761686526122824 | global_recall: 0.9603246167718665 | global_auc: 0.9954852608581898| flobal_FPR: 0.03967538322813345 \n",
      "comm_round: 12 | global_acc: 97.739% | global_loss: 0.07148665934801102 | global_f1: 0.969147005444646 | global_precision: 0.9753424657534246 | global_recall: 0.9630297565374211 | global_auc: 0.9956015956383478| flobal_FPR: 0.0369702434625789 \n",
      "comm_round: 13 | global_acc: 97.839% | global_loss: 0.07128112763166428 | global_f1: 0.970333181195801 | global_precision: 0.9824399260628466 | global_recall: 0.9585211902614968 | global_auc: 0.995666648148069| flobal_FPR: 0.04147880973850315 \n",
      "comm_round: 14 | global_acc: 98.105% | global_loss: 0.06956103444099426 | global_f1: 0.9741496598639456 | global_precision: 0.9799270072992701 | global_recall: 0.9684400360685302 | global_auc: 0.9957924796449747| flobal_FPR: 0.031559963931469794 \n",
      "comm_round: 15 | global_acc: 98.005% | global_loss: 0.0686722993850708 | global_f1: 0.9727272727272727 | global_precision: 0.9807516040329972 | global_recall: 0.9648331830477908 | global_auc: 0.9958371142136884| flobal_FPR: 0.0351668169522092 \n",
      "comm_round: 16 | global_acc: 98.271% | global_loss: 0.06841758638620377 | global_f1: 0.9764705882352942 | global_precision: 0.9800181653042689 | global_recall: 0.9729486023444545 | global_auc: 0.9959472761279607| flobal_FPR: 0.027051397655545536 \n",
      "comm_round: 17 | global_acc: 98.338% | global_loss: 0.06791652739048004 | global_f1: 0.9773755656108598 | global_precision: 0.9809264305177112 | global_recall: 0.9738503155996393 | global_auc: 0.9960123286376817| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 18 | global_acc: 98.404% | global_loss: 0.06741688400506973 | global_f1: 0.9782805429864253 | global_precision: 0.9818346957311535 | global_recall: 0.9747520288548241 | global_auc: 0.9960303723995022| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 19 | global_acc: 98.305% | global_loss: 0.06697150319814682 | global_f1: 0.976891708201178 | global_precision: 0.9817850637522769 | global_recall: 0.9720468890892696 | global_auc: 0.9960555386988833| flobal_FPR: 0.027953110910730387 \n",
      "comm_round: 20 | global_acc: 98.471% | global_loss: 0.0668904036283493 | global_f1: 0.9792043399638336 | global_precision: 0.9818676337262012 | global_recall: 0.9765554553651938 | global_auc: 0.9961486065230098| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 21 | global_acc: 98.172% | global_loss: 0.06735918670892715 | global_f1: 0.9750340444847935 | global_precision: 0.9817184643510055 | global_recall: 0.9684400360685302 | global_auc: 0.996065035415631| flobal_FPR: 0.031559963931469794 \n",
      "comm_round: 22 | global_acc: 98.404% | global_loss: 0.06665857136249542 | global_f1: 0.9783001808318263 | global_precision: 0.9809610154125114 | global_recall: 0.975653742110009 | global_auc: 0.9962046371518206| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 23 | global_acc: 98.371% | global_loss: 0.06660015881061554 | global_f1: 0.9778380823156942 | global_precision: 0.9809437386569873 | global_recall: 0.9747520288548241 | global_auc: 0.9962611426164689| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 24 | global_acc: 98.338% | global_loss: 0.06667624413967133 | global_f1: 0.9773960216998192 | global_precision: 0.9800543970988214 | global_recall: 0.9747520288548241 | global_auc: 0.9962972301401097| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 25 | global_acc: 98.338% | global_loss: 0.06699829548597336 | global_f1: 0.977416440831075 | global_precision: 0.9791855203619909 | global_recall: 0.975653742110009 | global_auc: 0.9963347421712628| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 26 | global_acc: 98.371% | global_loss: 0.0669807568192482 | global_f1: 0.9778781038374718 | global_precision: 0.9792043399638336 | global_recall: 0.9765554553651938 | global_auc: 0.996371304530741| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 27 | global_acc: 98.271% | global_loss: 0.06803446263074875 | global_f1: 0.9765765765765766 | global_precision: 0.9756975697569757 | global_recall: 0.9774571686203787 | global_auc: 0.9963565846197823| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 28 | global_acc: 98.271% | global_loss: 0.06863793730735779 | global_f1: 0.9766187050359711 | global_precision: 0.9739910313901345 | global_recall: 0.9792605951307484 | global_auc: 0.9963556349481075| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 29 | global_acc: 98.404% | global_loss: 0.06743559241294861 | global_f1: 0.978319783197832 | global_precision: 0.9800904977375565 | global_recall: 0.9765554553651938 | global_auc: 0.9963993198451465| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 30 | global_acc: 98.438% | global_loss: 0.06710194796323776 | global_f1: 0.978704123244223 | global_precision: 0.9836065573770492 | global_recall: 0.9738503155996393 | global_auc: 0.9963656065006925| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 31 | global_acc: 98.238% | global_loss: 0.069012351334095 | global_f1: 0.9761797752808989 | global_precision: 0.9731182795698925 | global_recall: 0.9792605951307484 | global_auc: 0.9963746283816028| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 32 | global_acc: 98.438% | global_loss: 0.0677030012011528 | global_f1: 0.978704123244223 | global_precision: 0.9836065573770492 | global_recall: 0.9738503155996393 | global_auc: 0.9963860244416999| flobal_FPR: 0.026149684400360685 \n",
      "comm_round: 33 | global_acc: 98.404% | global_loss: 0.06723888218402863 | global_f1: 0.9782805429864253 | global_precision: 0.9818346957311535 | global_recall: 0.9747520288548241 | global_auc: 0.9963978953376345| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 34 | global_acc: 98.371% | global_loss: 0.0674474909901619 | global_f1: 0.9778581111613194 | global_precision: 0.980072463768116 | global_recall: 0.975653742110009 | global_auc: 0.9964335080254378| flobal_FPR: 0.024346257889990983 \n",
      "comm_round: 35 | global_acc: 98.404% | global_loss: 0.06808538734912872 | global_f1: 0.978319783197832 | global_precision: 0.9800904977375565 | global_recall: 0.9765554553651938 | global_auc: 0.9964054927110324| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 36 | global_acc: 98.404% | global_loss: 0.0680377408862114 | global_f1: 0.9782805429864253 | global_precision: 0.9818346957311535 | global_recall: 0.9747520288548241 | global_auc: 0.9964449040855351| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 37 | global_acc: 98.438% | global_loss: 0.06848275661468506 | global_f1: 0.9787234042553192 | global_precision: 0.9827272727272728 | global_recall: 0.9747520288548241 | global_auc: 0.9964149894277801| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 38 | global_acc: 98.404% | global_loss: 0.06842280924320221 | global_f1: 0.9782805429864253 | global_precision: 0.9818346957311535 | global_recall: 0.9747520288548241 | global_auc: 0.9964354073687874| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 39 | global_acc: 98.404% | global_loss: 0.06867428123950958 | global_f1: 0.978319783197832 | global_precision: 0.9800904977375565 | global_recall: 0.9765554553651938 | global_auc: 0.9964297093387389| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 40 | global_acc: 98.471% | global_loss: 0.06918273866176605 | global_f1: 0.9791666666666666 | global_precision: 0.9836214740673339 | global_recall: 0.9747520288548241 | global_auc: 0.996441105398836| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 41 | global_acc: 98.438% | global_loss: 0.0691821277141571 | global_f1: 0.9787234042553192 | global_precision: 0.9827272727272728 | global_recall: 0.9747520288548241 | global_auc: 0.9964676962057292| flobal_FPR: 0.025247971145175834 \n",
      "comm_round: 42 | global_acc: 98.471% | global_loss: 0.06919082999229431 | global_f1: 0.9792043399638336 | global_precision: 0.9818676337262012 | global_recall: 0.9765554553651938 | global_auc: 0.9964828909525254| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 43 | global_acc: 98.471% | global_loss: 0.06954190135002136 | global_f1: 0.9792043399638336 | global_precision: 0.9818676337262012 | global_recall: 0.9765554553651938 | global_auc: 0.9964662716982171| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 44 | global_acc: 98.537% | global_loss: 0.06925377249717712 | global_f1: 0.9801264679313461 | global_precision: 0.9819004524886877 | global_recall: 0.9783588818755635 | global_auc: 0.9964700703849161| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 45 | global_acc: 98.471% | global_loss: 0.06960324198007584 | global_f1: 0.9792418772563176 | global_precision: 0.980126467931346 | global_recall: 0.9783588818755635 | global_auc: 0.9965170791328167| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 46 | global_acc: 98.504% | global_loss: 0.069896399974823 | global_f1: 0.979702300405954 | global_precision: 0.98014440433213 | global_recall: 0.9792605951307484 | global_auc: 0.9965113811027683| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 47 | global_acc: 98.471% | global_loss: 0.07055513560771942 | global_f1: 0.9792605951307484 | global_precision: 0.9792605951307484 | global_recall: 0.9792605951307484 | global_auc: 0.9965166042969795| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 48 | global_acc: 98.504% | global_loss: 0.07031851261854172 | global_f1: 0.9796839729119639 | global_precision: 0.9810126582278481 | global_recall: 0.9783588818755635 | global_auc: 0.9965213526553531| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 49 | global_acc: 98.504% | global_loss: 0.07066474854946136 | global_f1: 0.979702300405954 | global_precision: 0.98014440433213 | global_recall: 0.9792605951307484 | global_auc: 0.9964852651317124| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 50 | global_acc: 98.504% | global_loss: 0.07141466438770294 | global_f1: 0.9797388563710041 | global_precision: 0.9784172661870504 | global_recall: 0.9810640216411182 | global_auc: 0.9964672213698917| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 51 | global_acc: 98.504% | global_loss: 0.07145239412784576 | global_f1: 0.9796839729119639 | global_precision: 0.9810126582278481 | global_recall: 0.9783588818755635 | global_auc: 0.9965360725663119| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 52 | global_acc: 98.537% | global_loss: 0.0717865526676178 | global_f1: 0.9801444043321298 | global_precision: 0.981029810298103 | global_recall: 0.9792605951307484 | global_auc: 0.9965194533120036| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 53 | global_acc: 98.604% | global_loss: 0.07170706242322922 | global_f1: 0.9809954751131221 | global_precision: 0.9845594913714805 | global_recall: 0.9774571686203787 | global_auc: 0.9964852651317124| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 54 | global_acc: 98.537% | global_loss: 0.07199496030807495 | global_f1: 0.9801444043321298 | global_precision: 0.981029810298103 | global_recall: 0.9792605951307484 | global_auc: 0.9965052082368822| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 55 | global_acc: 98.537% | global_loss: 0.07322706282138824 | global_f1: 0.9801623083859333 | global_precision: 0.9801623083859333 | global_recall: 0.9801623083859333 | global_auc: 0.9965218274911906| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 56 | global_acc: 98.504% | global_loss: 0.07271579653024673 | global_f1: 0.979702300405954 | global_precision: 0.98014440433213 | global_recall: 0.9792605951307484 | global_auc: 0.996526101013727| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 57 | global_acc: 98.537% | global_loss: 0.07330199331045151 | global_f1: 0.9801623083859333 | global_precision: 0.9801623083859333 | global_recall: 0.9801623083859333 | global_auc: 0.9965332235512877| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 58 | global_acc: 98.637% | global_loss: 0.07366561144590378 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.996512330774443| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 59 | global_acc: 98.570% | global_loss: 0.0737755224108696 | global_f1: 0.9806044203879115 | global_precision: 0.9810469314079422 | global_recall: 0.9801623083859333 | global_auc: 0.996538446745499| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 60 | global_acc: 98.537% | global_loss: 0.07405996322631836 | global_f1: 0.9801623083859333 | global_precision: 0.9801623083859333 | global_recall: 0.9801623083859333 | global_auc: 0.9964999850426711| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 61 | global_acc: 98.570% | global_loss: 0.0741322785615921 | global_f1: 0.9806219017575485 | global_precision: 0.9801801801801802 | global_recall: 0.9810640216411182 | global_auc: 0.9965275255212391| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 62 | global_acc: 98.504% | global_loss: 0.07410332560539246 | global_f1: 0.9796839729119639 | global_precision: 0.9810126582278481 | global_recall: 0.9783588818755635 | global_auc: 0.9965443821934662| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 63 | global_acc: 98.637% | global_loss: 0.07477974146604538 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.996516129461142| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 64 | global_acc: 98.637% | global_loss: 0.07503506541252136 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.9965303745362635| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 65 | global_acc: 98.604% | global_loss: 0.07641969621181488 | global_f1: 0.9810981098109811 | global_precision: 0.9793351302785265 | global_recall: 0.9828674481514879 | global_auc: 0.9965242016703776| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 66 | global_acc: 98.637% | global_loss: 0.07532832771539688 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.996556015671482| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 67 | global_acc: 98.604% | global_loss: 0.07554666697978973 | global_f1: 0.9810640216411182 | global_precision: 0.9810640216411182 | global_recall: 0.9810640216411182 | global_auc: 0.9965524544027016| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 68 | global_acc: 98.604% | global_loss: 0.07567566633224487 | global_f1: 0.9810640216411182 | global_precision: 0.9810640216411182 | global_recall: 0.9810640216411182 | global_auc: 0.9965564905073193| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 69 | global_acc: 98.637% | global_loss: 0.07603803277015686 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.9965156546253047| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 70 | global_acc: 98.703% | global_loss: 0.07621736079454422 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9965569653431566| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 71 | global_acc: 98.404% | global_loss: 0.08332401514053345 | global_f1: 0.9784560143626571 | global_precision: 0.9740840035746202 | global_recall: 0.9828674481514879 | global_auc: 0.9965474686264091| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 72 | global_acc: 98.703% | global_loss: 0.07712483406066895 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.996533698387125| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 73 | global_acc: 98.670% | global_loss: 0.0773276761174202 | global_f1: 0.9819168173598554 | global_precision: 0.9845874886672711 | global_recall: 0.9792605951307484 | global_auc: 0.9965427202680353| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 74 | global_acc: 98.703% | global_loss: 0.07748393714427948 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9965332235512877| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 75 | global_acc: 98.670% | global_loss: 0.0776684358716011 | global_f1: 0.9819331526648599 | global_precision: 0.983710407239819 | global_recall: 0.9801623083859333 | global_auc: 0.9965555408356446| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 76 | global_acc: 98.703% | global_loss: 0.07781510800123215 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9965526918206203| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 77 | global_acc: 98.670% | global_loss: 0.08000533282756805 | global_f1: 0.9818840579710145 | global_precision: 0.986351228389445 | global_recall: 0.9774571686203787 | global_auc: 0.9965484182980838| flobal_FPR: 0.02254283137962128 \n",
      "comm_round: 78 | global_acc: 98.670% | global_loss: 0.07886351644992828 | global_f1: 0.9819168173598554 | global_precision: 0.9845874886672711 | global_recall: 0.9792605951307484 | global_auc: 0.9965258635958083| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 79 | global_acc: 98.703% | global_loss: 0.0786290243268013 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9965204029836785| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 80 | global_acc: 98.670% | global_loss: 0.07891765981912613 | global_f1: 0.9819494584837546 | global_precision: 0.982836495031617 | global_recall: 0.9810640216411182 | global_auc: 0.9965355977304746| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 81 | global_acc: 98.637% | global_loss: 0.08013854175806046 | global_f1: 0.9815398469158036 | global_precision: 0.9802158273381295 | global_recall: 0.9828674481514879 | global_auc: 0.9965512673131081| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 82 | global_acc: 98.637% | global_loss: 0.08002671599388123 | global_f1: 0.9815065403698692 | global_precision: 0.9819494584837545 | global_recall: 0.9810640216411182 | global_auc: 0.9965479434622465| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 83 | global_acc: 98.670% | global_loss: 0.07973410189151764 | global_f1: 0.9819494584837546 | global_precision: 0.982836495031617 | global_recall: 0.9810640216411182 | global_auc: 0.9965275255212391| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 84 | global_acc: 98.737% | global_loss: 0.07994690537452698 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9965227771628653| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 85 | global_acc: 98.703% | global_loss: 0.08038025349378586 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9965393964171736| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 86 | global_acc: 98.737% | global_loss: 0.08098108321428299 | global_f1: 0.9828674481514879 | global_precision: 0.9828674481514879 | global_recall: 0.9828674481514879 | global_auc: 0.9965541163281324| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 87 | global_acc: 98.670% | global_loss: 0.08103810250759125 | global_f1: 0.9819494584837546 | global_precision: 0.982836495031617 | global_recall: 0.9810640216411182 | global_auc: 0.9965417705963606| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 88 | global_acc: 98.737% | global_loss: 0.08108866214752197 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9965175539686542| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 89 | global_acc: 98.737% | global_loss: 0.08143299072980881 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9965185036403289| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 90 | global_acc: 98.737% | global_loss: 0.08109994977712631 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9965370222379868| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 91 | global_acc: 98.737% | global_loss: 0.08150428533554077 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9965265758495644| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 92 | global_acc: 98.737% | global_loss: 0.0820297822356224 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9964909631617609| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 93 | global_acc: 98.703% | global_loss: 0.08223357051610947 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9965071075802319| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 94 | global_acc: 98.670% | global_loss: 0.08269849419593811 | global_f1: 0.9819331526648599 | global_precision: 0.983710407239819 | global_recall: 0.9801623083859333 | global_auc: 0.9964781425941516| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 95 | global_acc: 98.703% | global_loss: 0.08298508822917938 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964933373409477| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 96 | global_acc: 98.703% | global_loss: 0.08310379832983017 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964966611918095| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 97 | global_acc: 98.670% | global_loss: 0.08347085863351822 | global_f1: 0.9819168173598554 | global_precision: 0.9845874886672711 | global_recall: 0.9792605951307484 | global_auc: 0.996485502549631| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 98 | global_acc: 98.637% | global_loss: 0.08390215039253235 | global_f1: 0.9815065403698692 | global_precision: 0.9819494584837545 | global_recall: 0.9810640216411182 | global_auc: 0.9965469937905718| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 99 | global_acc: 98.703% | global_loss: 0.08384862542152405 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9965042585652075| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 100 | global_acc: 98.703% | global_loss: 0.08383242785930634 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9965156546253047| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 101 | global_acc: 98.737% | global_loss: 0.08415459841489792 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9965028340576954| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 102 | global_acc: 98.703% | global_loss: 0.0843726247549057 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964957115201347| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 103 | global_acc: 98.737% | global_loss: 0.08435898274183273 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9965113811027682| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 104 | global_acc: 98.737% | global_loss: 0.0846647173166275 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9965042585652075| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 105 | global_acc: 98.737% | global_loss: 0.08481431752443314 | global_f1: 0.9828674481514879 | global_precision: 0.9828674481514879 | global_recall: 0.9828674481514879 | global_auc: 0.9965441447755474| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 106 | global_acc: 98.703% | global_loss: 0.08491507172584534 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9965379719096614| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 107 | global_acc: 98.737% | global_loss: 0.08514198660850525 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9965080572519066| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 108 | global_acc: 98.637% | global_loss: 0.08652272820472717 | global_f1: 0.9814563545906829 | global_precision: 0.984573502722323 | global_recall: 0.9783588818755635 | global_auc: 0.9965137552819552| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 109 | global_acc: 98.703% | global_loss: 0.08558043837547302 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9965239642524587| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 110 | global_acc: 98.737% | global_loss: 0.08588268607854843 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9964971360276469| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 111 | global_acc: 98.703% | global_loss: 0.08592232316732407 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9964805167733385| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 112 | global_acc: 98.703% | global_loss: 0.08621305972337723 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9965225397449466| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 113 | global_acc: 98.703% | global_loss: 0.08702240884304047 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964752935791272| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 114 | global_acc: 98.670% | global_loss: 0.08674243837594986 | global_f1: 0.9819168173598554 | global_precision: 0.9845874886672711 | global_recall: 0.9792605951307484 | global_auc: 0.9964750561612087| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 115 | global_acc: 98.703% | global_loss: 0.0867127850651741 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9965011721322646| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 116 | global_acc: 98.703% | global_loss: 0.08697911351919174 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9964852651317123| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 117 | global_acc: 98.703% | global_loss: 0.08705105632543564 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9964700703849162| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 118 | global_acc: 98.770% | global_loss: 0.08766376227140427 | global_f1: 0.9833107803337844 | global_precision: 0.983754512635379 | global_recall: 0.9828674481514879 | global_auc: 0.9964904883259234| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 119 | global_acc: 98.737% | global_loss: 0.0875244066119194 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9964919128334356| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 120 | global_acc: 98.637% | global_loss: 0.09128755331039429 | global_f1: 0.9814227458087903 | global_precision: 0.9863387978142076 | global_recall: 0.9765554553651938 | global_auc: 0.9964477531005593| flobal_FPR: 0.023444544634806132 \n",
      "comm_round: 121 | global_acc: 98.670% | global_loss: 0.08772793412208557 | global_f1: 0.9819331526648599 | global_precision: 0.983710407239819 | global_recall: 0.9801623083859333 | global_auc: 0.99649476184846| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 122 | global_acc: 98.737% | global_loss: 0.08797811716794968 | global_f1: 0.9828519855595668 | global_precision: 0.983739837398374 | global_recall: 0.981965734896303 | global_auc: 0.9964833657883627| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 123 | global_acc: 98.737% | global_loss: 0.08803194016218185 | global_f1: 0.9828519855595668 | global_precision: 0.983739837398374 | global_recall: 0.981965734896303 | global_auc: 0.9964847902958749| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 124 | global_acc: 98.670% | global_loss: 0.08878921717405319 | global_f1: 0.9819168173598554 | global_precision: 0.9845874886672711 | global_recall: 0.9792605951307484 | global_auc: 0.9964691207132415| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 125 | global_acc: 98.703% | global_loss: 0.0882822722196579 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964688832953227| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 126 | global_acc: 98.670% | global_loss: 0.08855321258306503 | global_f1: 0.9819331526648599 | global_precision: 0.983710407239819 | global_recall: 0.9801623083859333 | global_auc: 0.9964729193999404| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 127 | global_acc: 98.670% | global_loss: 0.08968354016542435 | global_f1: 0.981965734896303 | global_precision: 0.981965734896303 | global_recall: 0.981965734896303 | global_auc: 0.9964570123993882| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 128 | global_acc: 98.670% | global_loss: 0.08906133472919464 | global_f1: 0.9819168173598554 | global_precision: 0.9845874886672711 | global_recall: 0.9792605951307484 | global_auc: 0.9964805167733384| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 129 | global_acc: 98.770% | global_loss: 0.08908125758171082 | global_f1: 0.9833107803337844 | global_precision: 0.983754512635379 | global_recall: 0.9828674481514879 | global_auc: 0.9964914379975984| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 130 | global_acc: 98.703% | global_loss: 0.08943445980548859 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964852651317124| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 131 | global_acc: 98.670% | global_loss: 0.09036290645599365 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.99646033625025| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 132 | global_acc: 98.703% | global_loss: 0.09020452201366425 | global_f1: 0.982424515547544 | global_precision: 0.9819819819819819 | global_recall: 0.9828674481514879 | global_auc: 0.9964990353709964| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 133 | global_acc: 98.703% | global_loss: 0.08971293270587921 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964612859219246| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 134 | global_acc: 98.703% | global_loss: 0.08978817611932755 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964731568178591| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 135 | global_acc: 98.703% | global_loss: 0.09007579833269119 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9964612859219246| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 136 | global_acc: 98.737% | global_loss: 0.09007374942302704 | global_f1: 0.9828674481514879 | global_precision: 0.9828674481514879 | global_recall: 0.9828674481514879 | global_auc: 0.9964847902958749| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 137 | global_acc: 98.703% | global_loss: 0.09060655534267426 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964878767288179| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 138 | global_acc: 98.737% | global_loss: 0.09033524990081787 | global_f1: 0.9828674481514879 | global_precision: 0.9828674481514879 | global_recall: 0.9828674481514879 | global_auc: 0.9964809916091759| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 139 | global_acc: 98.737% | global_loss: 0.09061393141746521 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9964558253097948| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 140 | global_acc: 98.703% | global_loss: 0.09132029861211777 | global_f1: 0.982424515547544 | global_precision: 0.9819819819819819 | global_recall: 0.9828674481514879 | global_auc: 0.9964603362502498| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 141 | global_acc: 98.703% | global_loss: 0.09109241515398026 | global_f1: 0.982424515547544 | global_precision: 0.9819819819819819 | global_recall: 0.9828674481514879 | global_auc: 0.9964581994889816| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 142 | global_acc: 98.703% | global_loss: 0.09139762818813324 | global_f1: 0.9823609226594301 | global_precision: 0.985480943738657 | global_recall: 0.9792605951307484 | global_auc: 0.9964570123993882| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 143 | global_acc: 98.703% | global_loss: 0.09094272553920746 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9964738690716152| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 144 | global_acc: 98.737% | global_loss: 0.09124381840229034 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9964710200565909| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 145 | global_acc: 98.670% | global_loss: 0.0913579985499382 | global_f1: 0.9819494584837546 | global_precision: 0.982836495031617 | global_recall: 0.9810640216411182 | global_auc: 0.9965073449981504| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 146 | global_acc: 98.670% | global_loss: 0.09210570156574249 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.9964477531005593| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 147 | global_acc: 98.770% | global_loss: 0.09157618880271912 | global_f1: 0.9833107803337844 | global_precision: 0.983754512635379 | global_recall: 0.9828674481514879 | global_auc: 0.9964738690716152| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 148 | global_acc: 98.703% | global_loss: 0.0917825922369957 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9964729193999404| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 149 | global_acc: 98.670% | global_loss: 0.09227833151817322 | global_f1: 0.9819168173598554 | global_precision: 0.9845874886672711 | global_recall: 0.9792605951307484 | global_auc: 0.9964551130560386| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 150 | global_acc: 98.703% | global_loss: 0.09207063913345337 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9964700703849161| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 151 | global_acc: 98.703% | global_loss: 0.09215212613344193 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9964752935791272| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 152 | global_acc: 98.670% | global_loss: 0.09223894029855728 | global_f1: 0.9819494584837546 | global_precision: 0.982836495031617 | global_recall: 0.9810640216411182 | global_auc: 0.9964757684149647| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 153 | global_acc: 98.737% | global_loss: 0.0923282578587532 | global_f1: 0.9828674481514879 | global_precision: 0.9828674481514879 | global_recall: 0.9828674481514879 | global_auc: 0.9964762432508022| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 154 | global_acc: 98.737% | global_loss: 0.09238971769809723 | global_f1: 0.9828674481514879 | global_precision: 0.9828674481514879 | global_recall: 0.9828674481514879 | global_auc: 0.9964862148033871| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 155 | global_acc: 98.670% | global_loss: 0.0929492861032486 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.9964546382202013| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 156 | global_acc: 98.670% | global_loss: 0.09295693039894104 | global_f1: 0.9819331526648599 | global_precision: 0.983710407239819 | global_recall: 0.9801623083859333 | global_auc: 0.9964579620710631| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 157 | global_acc: 98.670% | global_loss: 0.09282488375902176 | global_f1: 0.9819494584837546 | global_precision: 0.982836495031617 | global_recall: 0.9810640216411182 | global_auc: 0.9964700703849162| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 158 | global_acc: 98.703% | global_loss: 0.09327135980129242 | global_f1: 0.982392776523702 | global_precision: 0.9837251356238698 | global_recall: 0.9810640216411182 | global_auc: 0.9964631852652741| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 159 | global_acc: 98.703% | global_loss: 0.09353245794773102 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964541633843639| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 160 | global_acc: 98.670% | global_loss: 0.09314943850040436 | global_f1: 0.9819494584837546 | global_precision: 0.982836495031617 | global_recall: 0.9810640216411182 | global_auc: 0.9964669839519731| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 161 | global_acc: 98.737% | global_loss: 0.09323425590991974 | global_f1: 0.9828674481514879 | global_precision: 0.9828674481514879 | global_recall: 0.9828674481514879 | global_auc: 0.996484790295875| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 162 | global_acc: 98.670% | global_loss: 0.09335093945264816 | global_f1: 0.9819494584837546 | global_precision: 0.982836495031617 | global_recall: 0.9810640216411182 | global_auc: 0.9964767180866395| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 163 | global_acc: 98.670% | global_loss: 0.09382364898920059 | global_f1: 0.9819331526648599 | global_precision: 0.983710407239819 | global_recall: 0.9801623083859333 | global_auc: 0.9964529762947705| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 164 | global_acc: 98.737% | global_loss: 0.09382738918066025 | global_f1: 0.9828674481514879 | global_precision: 0.9828674481514879 | global_recall: 0.9828674481514879 | global_auc: 0.9964843154600376| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 165 | global_acc: 98.703% | global_loss: 0.0935501828789711 | global_f1: 0.9824086603518268 | global_precision: 0.9828519855595668 | global_recall: 0.981965734896303 | global_auc: 0.9964793296837451| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 166 | global_acc: 98.637% | global_loss: 0.09380494803190231 | global_f1: 0.9814898419864561 | global_precision: 0.9828209764918626 | global_recall: 0.9801623083859333 | global_auc: 0.9964724445641031| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 167 | global_acc: 98.670% | global_loss: 0.09386545419692993 | global_f1: 0.9819331526648599 | global_precision: 0.983710407239819 | global_recall: 0.9801623083859333 | global_auc: 0.9964653220265425| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 168 | global_acc: 98.737% | global_loss: 0.09378279000520706 | global_f1: 0.9828519855595668 | global_precision: 0.983739837398374 | global_recall: 0.981965734896303 | global_auc: 0.996464134936949| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 169 | global_acc: 98.703% | global_loss: 0.09405753761529922 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964612859219246| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 170 | global_acc: 98.670% | global_loss: 0.09411884099245071 | global_f1: 0.9819331526648599 | global_precision: 0.983710407239819 | global_recall: 0.9801623083859333 | global_auc: 0.9964676962057293| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 171 | global_acc: 98.670% | global_loss: 0.09454664587974548 | global_f1: 0.9819004524886877 | global_precision: 0.9854677565849228 | global_recall: 0.9783588818755635 | global_auc: 0.9964444292496977| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 172 | global_acc: 98.703% | global_loss: 0.09418965131044388 | global_f1: 0.9824086603518268 | global_precision: 0.9828519855595668 | global_recall: 0.981965734896303 | global_auc: 0.9964824161166881| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 173 | global_acc: 98.703% | global_loss: 0.09420330077409744 | global_f1: 0.9824086603518268 | global_precision: 0.9828519855595668 | global_recall: 0.981965734896303 | global_auc: 0.9964743439074526| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 174 | global_acc: 98.703% | global_loss: 0.09427489340305328 | global_f1: 0.9824086603518268 | global_precision: 0.9828519855595668 | global_recall: 0.981965734896303 | global_auc: 0.9964764806687207| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 175 | global_acc: 98.737% | global_loss: 0.09441785514354706 | global_f1: 0.9828674481514879 | global_precision: 0.9828674481514879 | global_recall: 0.9828674481514879 | global_auc: 0.9964767180866394| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 176 | global_acc: 98.737% | global_loss: 0.09445154666900635 | global_f1: 0.9828519855595668 | global_precision: 0.983739837398374 | global_recall: 0.981965734896303 | global_auc: 0.9964710200565908| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 177 | global_acc: 98.703% | global_loss: 0.09472524374723434 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964669839519733| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 178 | global_acc: 98.703% | global_loss: 0.09495838731527328 | global_f1: 0.98237686398554 | global_precision: 0.9846014492753623 | global_recall: 0.9801623083859333 | global_auc: 0.9964657968623798| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 179 | global_acc: 98.737% | global_loss: 0.09478345513343811 | global_f1: 0.9828519855595668 | global_precision: 0.983739837398374 | global_recall: 0.981965734896303 | global_auc: 0.9964748187432899| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 180 | global_acc: 98.737% | global_loss: 0.09532924741506577 | global_f1: 0.9828209764918625 | global_precision: 0.985494106980961 | global_recall: 0.9801623083859333 | global_auc: 0.9964501272797461| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 181 | global_acc: 98.703% | global_loss: 0.09579475969076157 | global_f1: 0.9823449524671797 | global_precision: 0.9863636363636363 | global_recall: 0.9783588818755635 | global_auc: 0.9964325583537632| flobal_FPR: 0.02164111812443643 \n",
      "comm_round: 182 | global_acc: 98.737% | global_loss: 0.09555849432945251 | global_f1: 0.9828054298642535 | global_precision: 0.9863760217983651 | global_recall: 0.9792605951307484 | global_auc: 0.9964365944583808| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 183 | global_acc: 98.737% | global_loss: 0.09536249190568924 | global_f1: 0.9828209764918625 | global_precision: 0.985494106980961 | global_recall: 0.9801623083859333 | global_auc: 0.9964567749814695| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 184 | global_acc: 98.737% | global_loss: 0.0954640582203865 | global_f1: 0.9828209764918625 | global_precision: 0.985494106980961 | global_recall: 0.9801623083859333 | global_auc: 0.9964539259664451| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 185 | global_acc: 98.737% | global_loss: 0.09571782499551773 | global_f1: 0.9828054298642535 | global_precision: 0.9863760217983651 | global_recall: 0.9792605951307484 | global_auc: 0.9964460911751284| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 186 | global_acc: 98.670% | global_loss: 0.09547695517539978 | global_f1: 0.9819168173598554 | global_precision: 0.9845874886672711 | global_recall: 0.9792605951307484 | global_auc: 0.996458674324819| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 187 | global_acc: 98.737% | global_loss: 0.09553212672472 | global_f1: 0.9828364950316171 | global_precision: 0.9846153846153847 | global_recall: 0.9810640216411182 | global_auc: 0.9964650846086236| flobal_FPR: 0.018935978358881875 \n",
      "comm_round: 188 | global_acc: 98.670% | global_loss: 0.09816402196884155 | global_f1: 0.9819819819819819 | global_precision: 0.9810981098109811 | global_recall: 0.9828674481514879 | global_auc: 0.9964586743248192| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 189 | global_acc: 98.737% | global_loss: 0.09550152719020844 | global_f1: 0.9828519855595668 | global_precision: 0.983739837398374 | global_recall: 0.981965734896303 | global_auc: 0.9964631852652743| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 190 | global_acc: 98.703% | global_loss: 0.0959279015660286 | global_f1: 0.9823609226594301 | global_precision: 0.985480943738657 | global_recall: 0.9792605951307484 | global_auc: 0.9964532137126891| flobal_FPR: 0.020739404869251576 \n",
      "comm_round: 191 | global_acc: 98.703% | global_loss: 0.09571004658937454 | global_f1: 0.9824086603518268 | global_precision: 0.9828519855595668 | global_recall: 0.981965734896303 | global_auc: 0.99646935813116| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 192 | global_acc: 98.703% | global_loss: 0.09576933085918427 | global_f1: 0.9824086603518268 | global_precision: 0.9828519855595668 | global_recall: 0.981965734896303 | global_auc: 0.9964589117427377| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 193 | global_acc: 98.737% | global_loss: 0.09679152071475983 | global_f1: 0.9828674481514879 | global_precision: 0.9828674481514879 | global_recall: 0.9828674481514879 | global_auc: 0.9964506021155837| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 194 | global_acc: 98.770% | global_loss: 0.09614820033311844 | global_f1: 0.983295711060948 | global_precision: 0.984629294755877 | global_recall: 0.981965734896303 | global_auc: 0.9964503646976648| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 195 | global_acc: 98.737% | global_loss: 0.0970829501748085 | global_f1: 0.9828674481514879 | global_precision: 0.9828674481514879 | global_recall: 0.9828674481514879 | global_auc: 0.9964501272797461| flobal_FPR: 0.017132551848512173 \n",
      "comm_round: 196 | global_acc: 98.703% | global_loss: 0.0962425097823143 | global_f1: 0.9824086603518268 | global_precision: 0.9828519855595668 | global_recall: 0.981965734896303 | global_auc: 0.996472444564103| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 197 | global_acc: 98.737% | global_loss: 0.09649422019720078 | global_f1: 0.9828209764918625 | global_precision: 0.985494106980961 | global_recall: 0.9801623083859333 | global_auc: 0.9964460911751285| flobal_FPR: 0.019837691614066726 \n",
      "comm_round: 198 | global_acc: 98.737% | global_loss: 0.09631641209125519 | global_f1: 0.9828519855595668 | global_precision: 0.983739837398374 | global_recall: 0.981965734896303 | global_auc: 0.9964527388768517| flobal_FPR: 0.018034265103697024 \n",
      "comm_round: 199 | global_acc: 98.703% | global_loss: 0.0964282900094986 | global_f1: 0.9824086603518268 | global_precision: 0.9828519855595668 | global_recall: 0.981965734896303 | global_auc: 0.9964624730115181| flobal_FPR: 0.018034265103697024 \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'results\\round-200\\5-clients'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 215\u001b[0m\n\u001b[0;32m    213\u001b[0m all_R \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(all_results, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mglobal_acc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_f1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_precision\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_recall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_auc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mglobal_fpr\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    214\u001b[0m flname \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresults/round-\u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcl\u001b[39m}\u001b[39;00m\u001b[39m-clients/FedAvg-\u001b[39m\u001b[39m{\u001b[39;00mdataset[d]\u001b[39m}\u001b[39;00m\u001b[39m-results.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 215\u001b[0m all_R\u001b[39m.\u001b[39;49mto_csv(flname, index\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    217\u001b[0m all_avg\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mconcatenate(([dataset[d], r, cl], np\u001b[39m.\u001b[39mmean(all_results, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))))  \u001b[39m# Storing avg values for each dataset\u001b[39;00m\n\u001b[0;32m    218\u001b[0m all_std\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mconcatenate(([dataset[d], r, cl], np\u001b[39m.\u001b[39mstd(all_results, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))))  \u001b[39m# Storing std values for each dataset\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    733\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 734\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    737\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    595\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'results\\round-200\\5-clients'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train_model(model, train_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_avg = []\n",
    "all_std = []\n",
    "\n",
    "n_clients = [10]\n",
    "n_round = [200, 5000]\n",
    "\n",
    "dataset = ['Drebin', 'Malgenome', 'Kronodroid', 'Tuandromd']\n",
    "for d in range(0,1):\n",
    "    if d == 0:\n",
    "        use_data = Drebin_data\n",
    "    elif d == 1:\n",
    "        use_data = Malgenome_data\n",
    "    elif d == 2:\n",
    "        use_data = Kronodroid_data\n",
    "    elif d == 3:\n",
    "        use_data = Tuandromd_data\n",
    "\n",
    "    print('===================================================================================================')\n",
    "    print('Working with:', dataset[d])\n",
    "    print('===================================================================================================')\n",
    "\n",
    "    for r in n_round:  # number of rounds loop\n",
    "        comms_round = r\n",
    "        for cl in n_clients:  # number of clients loop\n",
    "            number_of_clients = cl\n",
    "\n",
    "            print('---------------------------------------------')\n",
    "            print('No. of Clients:', number_of_clients)\n",
    "            print('No. of Rounds:', comms_round)\n",
    "            print('---------------------------------------------')\n",
    "\n",
    "            features = np.array(use_data.iloc[:, range(0, use_data.shape[1] - 1)])  # feature set\n",
    "            labels = use_data.iloc[:, -1]  # labels --> B : Benign and S\n",
    "\n",
    "            # Do feature scaling\n",
    "            X = preprocessing.StandardScaler().fit(features).transform(features)\n",
    "\n",
    "            # binarize the labels\n",
    "            lb = LabelBinarizer()\n",
    "            y = lb.fit_transform(labels)\n",
    "\n",
    "            # split data into training and test set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                                y, shuffle=True,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=100)\n",
    "\n",
    "            # create clients -- Horizontal FL\n",
    "            print(\"asds\")\n",
    "            clients = create_non_iid_clients(X_train, y_train, num_clients=number_of_clients, initial='client')\n",
    "\n",
    "            # process and batch the training data for each client\n",
    "            clients_batched = dict()\n",
    "            for (client_name, data) in clients.items():\n",
    "                clients_batched[client_name] = batch_data(data)\n",
    "\n",
    "            # process and batch the test set\n",
    "            test_batched = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                                                                                     torch.tensor(y_test, dtype=torch.float32)),\n",
    "                                                       batch_size=len(y_test), shuffle=False)\n",
    "\n",
    "            # ==============================================\n",
    "            # Traditional FedAvg 2017\n",
    "            # ==============================================\n",
    "            # -----------------------------------------------\n",
    "\n",
    "            all_results = list()\n",
    "\n",
    "            # create optimizer\n",
    "            lr = 0.01\n",
    "            loss = nn.BCELoss()\n",
    "            optimizer = optim.SGD\n",
    "\n",
    "            # initialize global model\n",
    "            smlp_global = SimpleMLP(X.shape[1], 1)\n",
    "            global_model = smlp_global\n",
    "            # -----------------------------------------------\n",
    "\n",
    "            print('|=======================|')\n",
    "            print('|Traditional FedAvg 2017|')\n",
    "            print('|=======================|')\n",
    "\n",
    "            # commence global training loop\n",
    "            for comm_round in range(comms_round):\n",
    "                # get the global model's weights - will serve as the initial weights for all local models\n",
    "                global_weights = [param.data.clone() for param in global_model.parameters()]\n",
    "\n",
    "                # initial list to collect local model weights after scaling\n",
    "                scaled_local_weight_list = list()\n",
    "\n",
    "                # randomize client data - using keys\n",
    "                client_names = list(clients_batched.keys())\n",
    "                random.shuffle(client_names)\n",
    "\n",
    "                # ...\n",
    "\n",
    "                for client in client_names:\n",
    "                    smlp_local = SimpleMLP(X.shape[1], 1)\n",
    "                    local_model = smlp_local\n",
    "                    # set local model weight to the weight of the global model\n",
    "                    local_model.load_state_dict({name: param.clone() for name, param in zip(local_model.state_dict(), global_weights)})\n",
    "                    optimizer = torch.optim.SGD(local_model.parameters(), lr=0.01)\n",
    "\n",
    "                    # fit local model with client's data\n",
    "                    train_loader = DataLoader(TensorDataset(torch.tensor(clients_batched[client].dataset.tensors[0], dtype=torch.float32),\n",
    "                                                            torch.tensor(clients_batched[client].dataset.tensors[1], dtype=torch.float32)),\n",
    "                                              batch_size=32, shuffle=True)\n",
    "\n",
    "                    train_model(local_model, train_loader, loss, optimizer)\n",
    "\n",
    "\n",
    "                    # scale the model weights and add to the list\n",
    "                    scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "                    scaled_weights = scale_model_weights(local_model.state_dict().values(), scaling_factor)\n",
    "                    scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "                    # clear session to free memory after each communication round\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                # ...\n",
    "                \n",
    "                # to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "                average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "\n",
    "                # update global model\n",
    "                for param, avg_param in zip(global_model.parameters(), average_weights):\n",
    "                    param.data.copy_(avg_param)\n",
    "\n",
    "                # test global model and print out metrics after each communications round\n",
    "                for X_test_batch, Y_test_batch in test_batched:\n",
    "                    global_acc, global_loss, global_f1, global_precision, global_recall, global_auc, global_fpr = test_model(X_test_batch, Y_test_batch, global_model, comm_round)\n",
    "                    all_results.append([global_acc, global_loss, global_f1, global_precision, global_recall, global_auc, global_fpr])\n",
    "\n",
    "            all_R = pd.DataFrame(all_results, columns=['global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "            flname = f'results/round-{r}/{cl}-clients/FedAvg-{dataset[d]}-results.csv'\n",
    "            all_R.to_csv(flname, index=None)\n",
    "\n",
    "            all_avg.append(np.concatenate(([dataset[d], r, cl], np.mean(all_results, axis=0))))  # Storing avg values for each dataset\n",
    "            all_std.append(np.concatenate(([dataset[d], r, cl], np.std(all_results, axis=0))))  # Storing std values for each dataset\n",
    "\n",
    "ALL_AVG = pd.DataFrame(all_avg, columns=['Dataset', 'num of round', 'num of clients', 'global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv('FedAvg-results.csv')\n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns=['Dataset', 'num of round', 'num of clients', 'global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedAvg-all-std-results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((all_avg[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2893319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_avg =[]\n",
    "\n",
    "all_std =[]\n",
    "\n",
    "n_clients = [5,10,15]\n",
    "n_round = [10,20]\n",
    "\n",
    "\n",
    "dataset = ['Drebin', 'Malgenome', 'Kronodroid', 'Tuandromd' ]\n",
    "\n",
    "\n",
    "for d in range(0,1):\n",
    "    if d == 0:\n",
    "        use_data = Drebin_data\n",
    "    elif d==1:\n",
    "        use_data = Malgenome_data\n",
    "    elif d==2:\n",
    "        use_data = Kronodroid_data\n",
    "    elif d==3:\n",
    "        use_data = Tuandromd_data\n",
    "        \n",
    "        \n",
    "    print('===================================================================================================')\n",
    "    print('Working with:',dataset[d])\n",
    "    print('===================================================================================================')\n",
    "\n",
    "    for r in n_round: #number of rounds loop\n",
    "        comms_round = r\n",
    "        for cl in n_clients: #number of clients loop\n",
    "            number_of_clients = cl\n",
    "\n",
    "            # from sklearn.utils import shuffle\n",
    "            # use_data = shuffle(use_data)\n",
    "            # use_data\n",
    "            print('---------------------------------------------')\n",
    "            print('No. of Clients:', number_of_clients)\n",
    "            print('No. of Rounds:', comms_round)\n",
    "            print('---------------------------------------------')\n",
    "\n",
    "\n",
    "            features = np.array(use_data.iloc[:,range(0,use_data.shape[1]-1)]) #feature set\n",
    "\n",
    "            labels = use_data.iloc[:,-1] #labels --> B : Benign and S\n",
    "\n",
    "\n",
    "            #Do feature scaling \n",
    "\n",
    "\n",
    "            X = preprocessing.StandardScaler().fit(features).transform(features)\n",
    "\n",
    "\n",
    "            #binarize the labels\n",
    "            lb = LabelBinarizer()\n",
    "            y = lb.fit_transform(labels)\n",
    "\n",
    "\n",
    "            #split data into training and test set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                                y, shuffle=True,\n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=100)\n",
    "\n",
    "\n",
    "\n",
    "            #create clients -- Horizontal FL\n",
    "            clients = create_clients(X_train, y_train, num_clients=number_of_clients, initial='client')\n",
    "\n",
    "            #process and batch the training data for each client\n",
    "            clients_batched = dict()\n",
    "            for (client_name, data) in clients.items():\n",
    "                clients_batched[client_name] = batch_data(data)\n",
    "\n",
    "\n",
    "                #process and batch the test set  \n",
    "            test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "\n",
    "            #==============================================\n",
    "            # Traditional FedAvg 2017\n",
    "            #==============================================\n",
    "            #-----------------------------------------------\n",
    "\n",
    "\n",
    "            all_results=list()\n",
    "\n",
    "            #create optimizer\n",
    "            lr = 0.01 \n",
    "            loss='binary_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "            optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr, \n",
    "                            decay=lr / comms_round, \n",
    "                            momentum=0.9\n",
    "                           )\n",
    "\n",
    "            #initialize global model\n",
    "            smlp_global = SimpleMLP()\n",
    "            global_model = smlp_global.build(X.shape[1],1)\n",
    "            #-----------------------------------------------\n",
    "\n",
    "\n",
    "            print('|=======================|')\n",
    "            print('|Traditional FedAvg 2017|')\n",
    "            print('|=======================|')\n",
    "\n",
    "            #commence global training loop\n",
    "            for comm_round in range(comms_round):\n",
    "\n",
    "                # get the global model's weights - will serve as the initial weights for all local models\n",
    "                global_weights = global_model.get_weights()\n",
    "\n",
    "                #initial list to collect local model weights after scalling\n",
    "                scaled_local_weight_list = list()\n",
    "\n",
    "                #randomize client data - using keys\n",
    "                client_names= list(clients_batched.keys())\n",
    "                random.shuffle(client_names)\n",
    "\n",
    "                #loop through each client and create new local model\n",
    "                for client in client_names:\n",
    "                    smlp_local = SimpleMLP()\n",
    "                    local_model = smlp_local.build(X.shape[1],1)\n",
    "                    local_model.compile(loss=loss, \n",
    "                                  optimizer=optimizer, \n",
    "                                  metrics=metrics)\n",
    "\n",
    "                    #set local model weight to the weight of the global model\n",
    "                    local_model.set_weights(global_weights)\n",
    "\n",
    "                    #fit local model with client's data\n",
    "                    local_model.fit(clients_batched[client], epochs=32, verbose=0)\n",
    "\n",
    "                    #scale the model weights and add to list\n",
    "                    scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "                    scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "                    scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "                    #clear session to free memory after each communication round\n",
    "                    keras.backend.clear_session()\n",
    "\n",
    "                #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "                average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "\n",
    "                #update global model \n",
    "                global_model.set_weights(average_weights)\n",
    "\n",
    "                #test global model and print out metrics after each communications round\n",
    "                for(X_test, Y_test) in test_batched:\n",
    "                    global_acc, global_loss, global_f1, global_precision, global_recall, global_auc, global_fpr = test_model(X_test, Y_test, global_model, comm_round)\n",
    "                    all_results.append([global_acc,global_loss.numpy(),global_f1, global_precision, global_recall, global_auc, global_fpr])\n",
    "\n",
    "\n",
    "\n",
    "            all_R = pd.DataFrame(all_results, columns=['global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "            flname = 'results/round-'+str(r)+'/'+str(cl)+'-clients/FedAvg-'+dataset[d]+'-results.csv'\n",
    "            all_R.to_csv(flname, index=None)\n",
    "            \n",
    "            \n",
    "            all_avg.append(np.concatenate(([dataset[d],r,cl],np.mean(all_results,axis=0)))) #Storing avg values for each dataset\n",
    "            all_std.append(np.concatenate(([dataset[d],r,cl],np.std(all_results,axis=0)))) #Storing std values sfor each dataset\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "ALL_AVG = pd.DataFrame(all_avg, columns = ['Dataset', 'num of round', 'num of cliends','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv(f'FedAvg-results.csv')     \n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns = ['Dataset', 'num of round', 'num of cliends','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedAvg-all-std-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6104c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_AVG = pd.DataFrame(all_avg, columns = ['Dataset','Rounds','no-clients','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_AVG.to_csv('FedAvg-all-avg-results.csv')\n",
    "\n",
    "ALL_STD = pd.DataFrame(all_std, columns = ['Dataset','Rounds','no-clients','global_acc', 'global_loss', 'global_f1', 'global_precision', 'global_recall', 'global_auc', 'global_fpr'])\n",
    "ALL_STD.to_csv('FedAvg-all-std-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "# make a little extra space between the subplots\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "s1 = np.array(all_results) #FedAvg\n",
    "\n",
    "t = range(0,s1.shape[0])\n",
    "\n",
    "ax1.plot(t, s1[:,0],label='Acc of FedAvg')\n",
    "ax1.set_xlim(0,s1.shape[0])\n",
    "ax1.set_xlabel('Rounds')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim(0.98,1)\n",
    "ax1.grid(True)\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2.plot(t, s1[:,1],label='Error of FedAvg')\n",
    "ax2.set_xlim(0, s1.shape[0])\n",
    "ax2.set_xlabel('Rounds')\n",
    "ax2.set_ylabel('error')\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3861d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b54df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
